# Course 1: Neural Networks & Deep Learning

**Completed:** 2022 (Revisiting in 2025)

### What I Learned
- Logistic regression & shallow neural networks (NumPy from scratch)
- Activation functions: sigmoid, ReLU, tanh
- Gradient descent & backpropagation intuition
- Why vectorization matters for scaling

### My Takeaways
This course grounded me in the math behind neural networks.  
Rewriting backprop from scratch gave me an intuition I still use when debugging real models.